{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vDDaf-TNXfut"
   },
   "source": [
    "rules of the game : https://cdn.1j1ju.com/medias/85/5e/7c-pickomino-rulebook.pdf\n",
    "\n",
    "subject : https://team.inria.fr/polaris/files/2023/10/project_2023.pdf\n",
    "\n",
    "# PART 1: MDP for 1 player\n",
    "\n",
    "thoughout all the code, a worm is coded by the number 6, so choose dice 6 means choose the worm\n",
    "\n",
    "## Question 1\n",
    "\n",
    "We assumed that there was a additional 3 in the subject (otherwise there are 9 dices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 83754,
     "status": "ok",
     "timestamp": 1697569238851,
     "user": {
      "displayName": "Damien Lesens",
      "userId": "06426942432607513365"
     },
     "user_tz": -120
    },
    "id": "HnsT1en_Y7LS",
    "outputId": "97a734e3-03de-4342-f9fa-659e2caac700"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward vector: [1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4], losing cost: 0, dices: (1, 3, 3, 3, 4, 4, 5, 6)\n",
      "The optimal strategy is: Continue with dice 4, with expected value 1.3847052945245566\n"
     ]
    }
   ],
   "source": [
    "from dice_state import *\n",
    "from mdp import *\n",
    "\n",
    "c = 0 # value if you lose the turn\n",
    "r = [1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4]\n",
    "mdp = MDP(c,r)\n",
    "\n",
    "dices = (1, 3, 3, 3, 4, 4, 5, 6)\n",
    "score = 0\n",
    "used = set()\n",
    "state = DiceState(dices, score, used)\n",
    "\n",
    "mdp.explore(state)\n",
    "\n",
    "print(f\"Reward vector: {r}, losing cost: {c}, dices: {dices}\")\n",
    "print(f\"The optimal strategy is: {mdp.opti[state]}, with expected value {mdp.value[state]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 84528,
     "status": "ok",
     "timestamp": 1697569342211,
     "user": {
      "displayName": "Damien Lesens",
      "userId": "06426942432607513365"
     },
     "user_tz": -120
    },
    "id": "L1TT89_H_NWz",
    "outputId": "da81eb93-2a9c-4e42-a439-ef6c785a542b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward vector: [1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4], losing cost: -3, dices: (1, 3, 3, 3, 4, 4, 5, 6)\n",
      "The optimal strategy is: Continue with dice 6, with expected value 2.6654535643730695\n"
     ]
    }
   ],
   "source": [
    "from dice_state import *\n",
    "from mdp import *\n",
    "\n",
    "c = -3 # value if you lose the turn\n",
    "r = [1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4]\n",
    "mdp = MDP(c,r)\n",
    "\n",
    "dices = (1, 3, 3, 3, 4, 4, 5, 6)\n",
    "score = 0\n",
    "used = set()\n",
    "state = DiceState(dices, score, used)\n",
    "\n",
    "mdp.explore(state)\n",
    "\n",
    "print(f\"Reward vector: {r}, losing cost: {c}, dices: {dices}\")\n",
    "print(f\"The optimal strategy is: {mdp.opti[state]}, with expected value {mdp.value[state]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of obtaining a tile with 1 or more worms: 0.8930267371507402\n",
      "Probability of obtaining a tile with 2 or more worms: 0.6803307111795147\n",
      "Probability of obtaining a tile with 3 or more worms: 0.34629328714934327\n",
      "Probability of obtaining a tile with 4 or more worms: 0.08677521589317934\n"
     ]
    }
   ],
   "source": [
    "#Probability of obtaining a tile with i or more worms\n",
    "from mdp import *\n",
    "from dice_state import *\n",
    "\n",
    "def compute_worm_prob(worm : int):\n",
    "    c = 0 # value if you lose the turn\n",
    "    r = (4*worm) * [0] + [1]*(16 - 4*worm)\n",
    "    mdp = MDP(c,r)\n",
    "\n",
    "    mdp.explore_all()\n",
    "\n",
    "    return mdp.compute_value_total()\n",
    "\n",
    "for worm in range(4):\n",
    "    print(f\"Probability of obtaining a tile with {worm+1} or more worms: {compute_worm_prob(worm)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54292,
     "status": "ok",
     "timestamp": 1697569046562,
     "user": {
      "displayName": "Damien Lesens",
      "userId": "06426942432607513365"
     },
     "user_tz": -120
    },
    "id": "KNRgXzWF5W92",
    "outputId": "68c07b6e-7e2f-4fe6-b2c1-992d39f97566"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of getting exactly tile 24 is 0.3750601883516776\n"
     ]
    }
   ],
   "source": [
    "#Probability of getting exactly tile 24\n",
    "from mdp import *\n",
    "from dice_state import *\n",
    "\n",
    "c = 0 #value if you lose the turn\n",
    "r = [0,0,0,1] + [0]*100\n",
    "mdp = MDP(c,r)\n",
    "\n",
    "mdp.explore_all()\n",
    "\n",
    "p = mdp.compute_value_total()\n",
    "print(\"Probability of getting exactly tile 24 is\",p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54949,
     "status": "ok",
     "timestamp": 1697569112984,
     "user": {
      "displayName": "Damien Lesens",
      "userId": "06426942432607513365"
     },
     "user_tz": -120
    },
    "id": "FMio81Gh6UBb",
    "outputId": "2cf09edf-0830-4096-a0d1-e809c456dba2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of getting tile 27 of more is 0.5247594468429359\n"
     ]
    }
   ],
   "source": [
    "#Probability of getting tile 27 or more\n",
    "from mdp import *\n",
    "from dice_state import *\n",
    "\n",
    "c = 0 #value if you lose the turn\n",
    "r = [0,0,0,0,0,0,1] + [1]*100\n",
    "mdp = MDP(c,r)\n",
    "\n",
    "mdp.explore_all()\n",
    "\n",
    "p = mdp.compute_value_total()\n",
    "print(\"Probability of getting tile 27 of more is\",p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifications\n",
    "\n",
    "You can see here that we get the same values than the verification values provided on the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "kco3hxeu6SsB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continue with dice 4 value is 1.5035075126898982\n"
     ]
    }
   ],
   "source": [
    "#Verification mdp\n",
    "from dice_state import *\n",
    "from mdp import *\n",
    "\n",
    "c = 0 #value if you lose the turn\n",
    "r = [1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4] + [4]*100\n",
    "mdp = MDP(c,r)\n",
    "\n",
    "dices = (1, 1, 2, 4, 4, 4, 5, 6)\n",
    "score = 0\n",
    "used = set()\n",
    "state = DiceState(dices, score, used)\n",
    "\n",
    "mdp.explore(state)\n",
    "\n",
    "print(mdp.opti[state], \"value is\", mdp.value[state] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continue with dice 6 value is 1.0007739864349952\n",
      "The expected value for keeping the 2 four is: 0.8577674897119344\n"
     ]
    }
   ],
   "source": [
    "#Verification mdp\n",
    "from dice_state import *\n",
    "from mdp import *\n",
    "\n",
    "c = 0 #value if you lose the turn\n",
    "r = [1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4] + [4]*100\n",
    "mdp = MDP(c,r)\n",
    "\n",
    "dices = (1, 3, 4, 4, 6)\n",
    "score = 9\n",
    "used = {3}\n",
    "state = DiceState(dices, score, used)\n",
    "\n",
    "mdp.explore(state)\n",
    "\n",
    "print(mdp.opti[state], \"value is\", mdp.value[state] )\n",
    "#keeping the 2 four\n",
    "state2 = (9+8,tuple({3,4}),3)\n",
    "print(\"The expected value for keeping the 2 four is:\",mdp.value_diceless[state2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "should stop : False, value is 1.7256944444444444\n"
     ]
    }
   ],
   "source": [
    "#Verification mdp\n",
    "from dice_state import *\n",
    "from mdp import *\n",
    "\n",
    "c = 0 #value if you lose the turn\n",
    "r = [1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4] + [4]*100\n",
    "mdp = MDP(c,r)\n",
    "\n",
    "score = 23\n",
    "used = {3,5,6}\n",
    "nbdice = 3\n",
    "\n",
    "state2 = score, tuple(used), nbdice\n",
    "\n",
    "mdp.explore_diceless(state2)\n",
    "\n",
    "print(f\"should stop : {mdp.should_stop[state2]}, value is {mdp.value_diceless[state2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "should stop : True, value is 1 \n"
     ]
    }
   ],
   "source": [
    "#Verification mdp\n",
    "from dice_state import *\n",
    "from mdp import *\n",
    "\n",
    "c = 0 #value if you lose the turn\n",
    "r = [1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4] + [4]*100\n",
    "mdp = MDP(c,r)\n",
    "\n",
    "score = 21\n",
    "used = {2,3,4,6}\n",
    "nbdice = 2\n",
    "\n",
    "state2 = score, tuple(used), nbdice\n",
    "\n",
    "mdp.explore_diceless(state2)\n",
    "\n",
    "print(f\"should stop : {mdp.should_stop[state2]}, value is {mdp.value_diceless[state2]} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 : Learning\n",
    "\n",
    "For this part, we recommend you to us ethe smaller board by modifying the constants in `constants.py`.\n",
    "\n",
    "\n",
    "Here is an example of two alpha-beta players playing a game. You can still run it with the large constants, it takes 6.5 sec for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winner is PlayerTurn.PLAYER_2\n"
     ]
    }
   ],
   "source": [
    "from alpha_beta_player import AlphaBetaPlayer\n",
    "from dice_state import DiceState\n",
    "from run_game import *\n",
    "\n",
    "p1 = AlphaBetaPlayer(1.0, 1.0)\n",
    "p2 = AlphaBetaPlayer(1.5, 0.5)\n",
    "\n",
    "w = run_game(p1, p2)\n",
    "print(f\"Winner is {w}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best alpha-beta player\n",
    "\n",
    "Using UCB with discrete parameters. \n",
    "- For the small board, we can run $5000$ games with a $10 \\times 10$ parameter grid in `8 minutes`\n",
    "- For the normal board, we can run $100$ games with a $5 \\times 5$ parameter grid in `14 minutes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucb import *\n",
    "from constants import SMALL_BOARD\n",
    "from alpha_beta_player import AlphaBetaPlayer\n",
    "\n",
    "\n",
    "adversary = AlphaBetaPlayer(1,1)\n",
    "\n",
    "if SMALL_BOARD:\n",
    "    num_games = 5000\n",
    "    grid_size = 10\n",
    "else:\n",
    "    num_games = 100\n",
    "    grid_size = 5\n",
    "\n",
    "best_pair, best_winrate = simulate_games_ucb(adversary, grid_size, num_games)\n",
    "print(f\"The best pair against (1,1) is: {best_pair} with a winrate of {best_winrate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing against fixed alpha-beta\n",
    "\n",
    "We used policy gradient. Details about the feature vector we used can be found in the code and the report.\n",
    "\n",
    "Here is an example of gradient descent.\n",
    "\n",
    "We are not sure about the parameters to use for this part.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reinforce import *\n",
    "from constants import *\n",
    "from feature_map import *\n",
    "\n",
    "w0 = np.array([1 for _ in range(NUM_FEATURES)])\n",
    "\n",
    "pr = Reinforce(w0,1,1,phi,0.95)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for 2000 games takes 40 sec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0\n",
      "w: [1 1 1 1 1 1 1 1 1 1]\n",
      "gradient norm: 4.535343703429935\n",
      "step: 100\n",
      "w: [0.96381836 1.23958318 1.24150919 0.70290218 1.14532247 1.54553747\n",
      " 0.94419664 0.93508592 1.41264382 1.11657659]\n",
      "gradient norm: 1.7567075619013879\n",
      "step: 200\n",
      "w: [1.427683   1.44048345 1.24280257 0.63909936 1.15773282 2.26562052\n",
      " 0.94056609 0.94022109 1.43745576 1.14256404]\n",
      "gradient norm: 3.790739514910061\n",
      "step: 300\n",
      "w: [1.15900871 1.74242134 1.22764873 1.20607311 1.04420061 2.77402529\n",
      " 1.05563271 0.97342421 1.29310278 1.00037832]\n",
      "gradient norm: 8.17301462991429\n",
      "step: 400\n",
      "w: [1.78045385 1.56761253 1.22855663 1.33267209 1.01906456 2.86726378\n",
      " 1.08075942 0.97155257 1.22601549 0.93334126]\n",
      "gradient norm: 12.141070279769117\n",
      "step: 500\n",
      "w: [2.27825863 1.38466179 1.30048675 1.40436548 1.01911359 2.5714858\n",
      " 1.08071321 0.97088398 1.2260083  0.93333403]\n",
      "gradient norm: 3.0859995405074634\n",
      "step: 600\n",
      "w: [2.0889015  1.43654495 1.30072766 1.40463505 1.01911155 2.5968033\n",
      " 1.08071672 0.97050722 1.2260037  0.93332147]\n",
      "gradient norm: 5.827868917041638\n",
      "step: 700\n",
      "w: [1.53756792 1.78210096 1.29659739 1.40534893 1.01799228 3.07571839\n",
      " 1.08184487 0.98593571 1.22340411 0.93072127]\n",
      "gradient norm: 10.642994810781206\n",
      "step: 800\n",
      "w: [2.02631232 1.704179   1.29789963 1.40665524 1.01799165 3.0097792\n",
      " 1.08184563 0.98291439 1.22341479 0.93071986]\n",
      "gradient norm: 26.260821985471832\n",
      "step: 900\n",
      "w: [1.55879286 1.98105912 1.29539132 1.405399   1.0176066  3.17980675\n",
      " 1.08213625 0.9904449  1.22273885 0.93004465]\n",
      "gradient norm: 5.878999511805476\n",
      "step: 1000\n",
      "w: [1.35775589 2.09965752 1.29702579 1.40396645 1.01837348 3.34424075\n",
      " 1.08085493 0.9835389  1.22451871 0.93184026]\n",
      "gradient norm: 0.5396559727358574\n",
      "step: 1100\n",
      "w: [2.15343604 1.8251325  1.30181905 1.38377388 1.02305598 3.23355515\n",
      " 1.07305087 0.98591736 1.23073913 0.93807481]\n",
      "gradient norm: 0.34872966296476865\n",
      "step: 1200\n",
      "w: [1.81240251 2.04402009 1.32542875 1.28553071 1.04742854 3.45343292\n",
      " 1.03243094 0.97181562 1.26322574 0.97057158]\n",
      "gradient norm: 3.0770842756276875\n",
      "step: 1300\n",
      "w: [1.60370311 2.19139204 1.32605858 1.28612443 1.04743662 3.69986665\n",
      " 1.03241753 0.96932695 1.26322647 0.97058012]\n",
      "gradient norm: 0.8846474712800276\n",
      "step: 1400\n",
      "w: [2.10959784 2.04206934 1.36018246 0.71622951 1.12676447 3.64782051\n",
      " 0.852612   1.00266427 1.83646107 1.29161154]\n",
      "gradient norm: 1.5170312270478827\n",
      "step: 1500\n",
      "w: [3.01712323 1.71376958 1.36085713 1.17095396 1.0253407  3.2769661\n",
      " 1.03996797 1.00210718 1.69544704 1.14729027]\n",
      "gradient norm: 0.13414931865912483\n",
      "step: 1600\n",
      "w: [3.24127244 1.62091402 1.3630428  0.95356861 1.08419192 3.24133141\n",
      " 1.01917609 0.98901529 1.80406003 1.25592581]\n",
      "gradient norm: 12.849176717310465\n",
      "step: 1700\n",
      "w: [3.07458168 1.62540228 1.33104301 1.07416557 1.05742235 3.21257399\n",
      " 1.05319732 1.01596146 1.83550621 1.28727519]\n",
      "gradient norm: 2.0877357134056345\n",
      "step: 1800\n",
      "w: [3.15733772 1.63953254 1.32930572 1.73756102 0.93817763 3.12560796\n",
      " 1.2298778  1.01714651 1.6465101  1.09825707]\n",
      "gradient norm: 2.9605183956588377\n",
      "step: 1900\n",
      "w: [3.12473458 1.6718923  1.32904787 1.73728923 0.93818079 3.29769372\n",
      " 1.22987371 1.01782979 1.64651536 1.09826232]\n",
      "gradient norm: 0.2609591202012533\n"
     ]
    }
   ],
   "source": [
    "pr.train(2000,0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the performance over 500 games takes 10sec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr.evaluate(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.07817999 -2.61937355  0.85869885  1.12038423  2.77553292  6.31692917\n",
      "  1.04826051  1.31944893  1.05957952]\n"
     ]
    }
   ],
   "source": [
    "print(pr.w)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1vDMIx-ai2g4im_qNFK57JmsGba2q4Bc5",
     "timestamp": 1697629760854
    }
   ]
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.10.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
